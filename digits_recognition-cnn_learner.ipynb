{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wv_B_OCuWUub"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get all data"
      ],
      "metadata": {
        "id": "Rl9fFjGm7e3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(dir(URLs))\n",
        "path_mnist = untar_data(URLs.MNIST)"
      ],
      "metadata": {
        "id": "fc3OYGcQ7erT",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open all entries in the training set"
      ],
      "metadata": {
        "id": "H270h0Dhpl0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_0_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'0').ls()])\n",
        "train_1_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'1').ls()])\n",
        "train_2_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'2').ls()])\n",
        "train_3_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'3').ls()])\n",
        "train_4_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'4').ls()])\n",
        "train_5_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'5').ls()])\n",
        "train_6_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'6').ls()])\n",
        "train_7_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'7').ls()])\n",
        "train_8_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'8').ls()])\n",
        "train_9_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'training'/'9').ls()])"
      ],
      "metadata": {
        "id": "fYfy7SKjSbnp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = (torch.cat( [train_0_tensors,\n",
        "                       train_1_tensors,\n",
        "                       train_2_tensors,\n",
        "                       train_3_tensors,\n",
        "                       train_4_tensors,\n",
        "                       train_5_tensors,\n",
        "                       train_6_tensors,\n",
        "                       train_7_tensors,\n",
        "                       train_8_tensors,\n",
        "                       train_9_tensors]).float()/255).view(-1, 1, 28, 28)\n",
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ysct4NkUitk",
        "outputId": "26ae40f3-2e1a-476a-df64-9780c8a74933"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = torch.cat(  [torch.stack([tensor(1, 0, 0, 0, 0, 0, 0, 0, 0, 0)] * len(train_0_tensors)),\n",
        "                       torch.stack([tensor(0, 1, 0, 0, 0, 0, 0, 0, 0, 0)] * len(train_1_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 1, 0, 0, 0, 0, 0, 0, 0)] * len(train_2_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 1, 0, 0, 0, 0, 0, 0)] * len(train_3_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 1, 0, 0, 0, 0, 0)] * len(train_4_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 1, 0, 0, 0, 0)] * len(train_5_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 1, 0, 0, 0)] * len(train_6_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 0, 1, 0, 0)] * len(train_7_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 0, 0, 1, 0)] * len(train_8_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 0, 0, 0, 1)] * len(train_9_tensors))]).float()\n",
        "train_y\n",
        "train_y = train_y.argmax(dim=1).long()\n",
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4Kr4uy3vTzF",
        "outputId": "ce0d7255-0d27-4d12-bc30-96e12aa55c75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 9, 9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dset = list(zip(train_x, train_y))\n",
        "train_dl = DataLoader(train_dset, batch_size=256)"
      ],
      "metadata": {
        "id": "7w1AhcHHWIHr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open all entries in the validation set"
      ],
      "metadata": {
        "id": "hY-gdg7KpcyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_0_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'0').ls()])\n",
        "valid_1_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'1').ls()])\n",
        "valid_2_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'2').ls()])\n",
        "valid_3_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'3').ls()])\n",
        "valid_4_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'4').ls()])\n",
        "valid_5_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'5').ls()])\n",
        "valid_6_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'6').ls()])\n",
        "valid_7_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'7').ls()])\n",
        "valid_8_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'8').ls()])\n",
        "valid_9_tensors = torch.stack([tensor(Image.open(o)) for o in (path_mnist/'testing'/'9').ls()])"
      ],
      "metadata": {
        "id": "vJTETpSrQPn-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_x = (torch.cat( [valid_0_tensors,\n",
        "                       valid_1_tensors,\n",
        "                       valid_2_tensors,\n",
        "                       valid_3_tensors,\n",
        "                       valid_4_tensors,\n",
        "                       valid_5_tensors,\n",
        "                       valid_6_tensors,\n",
        "                       valid_7_tensors,\n",
        "                       valid_8_tensors,\n",
        "                       valid_9_tensors]).float()/255).view(-1, 1, 28, 28)\n",
        "valid_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vrkv13eQ4T6",
        "outputId": "1a3f391a-3293-4da8-e49a-f1a732c4d47c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_y = torch.cat(  [torch.stack([tensor(1, 0, 0, 0, 0, 0, 0, 0, 0, 0)] * len(valid_0_tensors)),\n",
        "                       torch.stack([tensor(0, 1, 0, 0, 0, 0, 0, 0, 0, 0)] * len(valid_1_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 1, 0, 0, 0, 0, 0, 0, 0)] * len(valid_2_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 1, 0, 0, 0, 0, 0, 0)] * len(valid_3_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 1, 0, 0, 0, 0, 0)] * len(valid_4_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 1, 0, 0, 0, 0)] * len(valid_5_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 1, 0, 0, 0)] * len(valid_6_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 0, 1, 0, 0)] * len(valid_7_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 0, 0, 1, 0)] * len(valid_8_tensors)),\n",
        "                       torch.stack([tensor(0, 0, 0, 0, 0, 0, 0, 0, 0, 1)] * len(valid_9_tensors))]).float()\n",
        "valid_y\n",
        "valid_y = valid_y.argmax(dim=1).long()\n",
        "valid_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0T4c5GGpCpo",
        "outputId": "04fd67ab-1c80-41e0-cb10-1ad852d3525e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 9, 9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dset = list(zip(valid_x, valid_y))\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "metadata": {
        "id": "lpgpRXb8vX3v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define DataLoaders from the DataLoader for training data and the DataLoader from the validation data"
      ],
      "metadata": {
        "id": "uM41_P9z2F6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digit_dls = DataLoaders(train_dl, valid_dl)"
      ],
      "metadata": {
        "id": "1-gvPE4I2Q8e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learn = vision_learner(digit_dls, resnet18, pretrained=False, loss_func=CrossEntropyLossFlat(), metrics=accuracy, n_out=10, n_in=1)"
      ],
      "metadata": {
        "id": "m8RbkH1h1Mg7"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learn.fit_one_cycle(1, 0.1)"
      ],
      "metadata": {
        "id": "WudBzfrCwKz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "small_train = Subset(digit_dls.train_ds, range(2048))\n",
        "small_valid = Subset(digit_dls.valid_ds, range(512))\n",
        "small_dls = DataLoaders.from_dsets(small_train, small_valid, bs=256, shuffle=True)\n",
        "\n",
        "learn = vision_learner(\n",
        "    small_dls, resnet18,\n",
        "    pretrained=False, n_in=1, n_out=10,\n",
        "    loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "    normalize=False\n",
        ")\n",
        "\n",
        "learn.fit_one_cycle(1, 1e-3)"
      ],
      "metadata": {
        "id": "Ir9I1X_Fv4G2",
        "outputId": "dad11412-891f-4142-8cf1-3e9a126eb679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.654000</td>\n",
              "      <td>1.539730</td>\n",
              "      <td>0.998047</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}